{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leesuyee/ups_nrsc490_tutorial/blob/main/NRSC_490_Tutorial_Credit_Assignment_During_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3234d52-9aff-403b-8077-4ad5535661b8",
      "metadata": {
        "id": "a3234d52-9aff-403b-8077-4ad5535661b8"
      },
      "source": [
        "<h1>How do neuron interactions change after learning? </h2>\n",
        "<h2> Credit Assignment During Learning: Data Access Tutorial\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Sept 24, 2025\n",
        "\n",
        "NRSC 490\n",
        "\n",
        "University of Puget Sound\n",
        "\n",
        "Su-Yee Lee, Saskia de Vries, Marina Garrett, Kayvon Daie, Marton Rozsa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac3ea999",
      "metadata": {
        "id": "ac3ea999"
      },
      "source": [
        "# **Overview**\n",
        "    \n",
        "In this tutorial, we'll use neural activity data collected from mouse primary motor cortex before, during, and after animals learn a brain-computer interface task to address the following question: **How do neuron interactions change after learning?**\n",
        "\n",
        "The data we're working with is part of the ongoing [Credit Assignment During Learning](https://www.allenneuraldynamics.org/projects/credit-assignment-during-learning)\n",
        "project at the Allen Institute for Neural Dynamics. In this experiment, mice learn to control the activity of a specific neuron in order to receive rewards using a brain computer interface (BCI) paradigm. The activity of the conditioned neuron is read out in real time and is linked to the movement of a reward spot. Over a few trials, the activity of the conditioned neuron becomes coupled to the movement of the spout and the mouse learns to activate that neuron to move the spout towards its mouth to receive a reward. In contrast to other behavior tasks, this task enables us to study how learning of a single neuron can affect other cells in the network. See below for additional details of this dataset.\n",
        "\n",
        "## **Background:**\n",
        " This experiment was designed to test competing models of learning rules—such as Hebbian learning,\n",
        " long-range input modulation, and biologically plausible approximations of error backpropagation—by\n",
        " directly measuring changes in neural activity and inferred connectivity during learning.\n",
        " The core task involved a closed-loop BCI paradigm in which a single neuron’s activity controlled\n",
        " a reward mechanism. Because the mapping from activity to behavior was fully defined by the experimenter,\n",
        "  this paradigm enables ground-truth labeling of neurons as behaviorally causal (e.g., the conditioned neuron) versus merely correlated.\n",
        "    \n",
        "To probe learning-related circuit changes, cellular-resolution two-photon photostimulation\n",
        " was used to perturb neurons before and after learning. By analyzing evoked responses,\n",
        " researchers could infer the presence and strength of functional connections.\n",
        " Learning-induced changes in connectivity were then compared to predictions\n",
        " from recurrent neural network models trained with different plasticity rules,\n",
        " enabling discrimination between competing learning algorithms.\n",
        "    \n",
        "## **Experiment:**\n",
        "Neural activity was recorded from layer 2/3 excitatory neurons in the primary motor cortex\n",
        "of head-fixed mice using two-photon calcium imaging. Imaging was performed over multiple days\n",
        " as each animal learned and performed a BCI task. Each day, a new conditioned neuron (CN) was selected,\n",
        " the activity of this neuron was mapped in real-time to the position of a motorized reward port.\n",
        " To receive water rewards, mice had to learn to increase the activity of the conditioned neuron to move the port into reach.\n",
        "\n",
        "In addition to the BCI task, the dataset includes photostimulation blocks in which individual or\n",
        "groups of neurons were optogenetically stimulated to assess their causal influence on the surrounding network.\n",
        "These connection mapping sessions were repeated daily to measure how connectivity changed as learning progressed.\n",
        " Imaging data were preprocessed using Suite2p or CellPose and include motion-corrected fluorescence traces,\n",
        " extracted ROIs, inferred spiking events, and stimulus-aligned behavioral data.\n",
        "    \n",
        "## **Approach: What analysis method can we use to address this question?**\n",
        "\n",
        "One simple way to assess neuron interactions is by quantifying how correlated their activity patterns are. If neurons are consistently co-active, they are causally connected - likely connected directly or indirectly or receive shared input as part of an interacting circuit.\n",
        "\n",
        "## **Goals:**\n",
        "\n",
        "This tutorial focuses on data access, session structure (photostimulation and task periods), correlation structure among populations of neurons, and relating correlations to anatomical distance between cells.  \n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Resources**\n",
        "\n",
        "For more details on the dataset, please refer to our online data book: https://allenswdb.github.io/physiology/ophys/BCI/BCI-overview.html"
      ],
      "metadata": {
        "id": "miWksDsycx-f"
      },
      "id": "miWksDsycx-f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ebP_59VfFsU2"
      },
      "id": "ebP_59VfFsU2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set up environment**\n",
        "\n",
        "Run the cell below to pip install the necessary packages. After install, restart the session and start at the next cell.\n",
        "\n",
        "## **DO NOT RERUN THIS CELL**\n"
      ],
      "metadata": {
        "id": "IpOeuKkmePxG"
      },
      "id": "IpOeuKkmePxG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up environment\n",
        "\n",
        "!pip install pandas==2.2.3\n",
        "!pip install aind-data-access-api==1.2.1\n",
        "!pip install datetime\n",
        "\n",
        "# Pin numpy to <2.0 for compatibility with hdmf/pynwb/hdmf-zarr\n",
        "# Use matplotlib <3.9 since 3.10+ has breaking changes with Colab rendering\n",
        "!pip install \"numpy<2.0\" \"matplotlib<3.9\" \\\n",
        "    hdmf==3.14.6 \\\n",
        "    hdmf-zarr==0.11.3 \\\n",
        "    pynwb==3.0.0 \\\n",
        "    s3fs \\\n",
        "    scikit-image \\\n",
        "    scipy\n"
      ],
      "metadata": {
        "id": "yzCy9Yhg_2VV"
      },
      "id": "yzCy9Yhg_2VV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f58c63ce-83ab-466f-8ab0-1f41411aad80",
      "metadata": {
        "id": "f58c63ce-83ab-466f-8ab0-1f41411aad80"
      },
      "source": [
        "# **Import packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8dc594-cbae-4e3e-8b45-a826d7be7417",
      "metadata": {
        "id": "5d8dc594-cbae-4e3e-8b45-a826d7be7417"
      },
      "outputs": [],
      "source": [
        "#General imports\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import scipy.stats as stats\n",
        "from skimage import measure\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import s3fs\n",
        "\n",
        "#PyNWB imports\n",
        "from hdmf_zarr import NWBZarrIO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import metadata**\n",
        "\n",
        "For each experimental session, the experimenters collect rich metadata that reports important information about the equipment, materials, and methods used. The metadata records helps data users understand what happened during the experiment to select sessions of interest to analyze further.  \n",
        "\n",
        "Run the hidden code cell below to import the metadata records from our database. Note that we have pre-selected sessions and metadata fields that are relevant for this tutorial. The code outputs a dataframe that contains information about the experimental session, such as the time/date of the session, the genotype and virus information of the subject, and other experimental parameters."
      ],
      "metadata": {
        "id": "qoK-h80bfJNp"
      },
      "id": "qoK-h80bfJNp"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to import metadata from DocDB\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime, date\n",
        "from aind_data_access_api.document_db import MetadataDbClient\n",
        "\n",
        "API_GATEWAY_HOST = \"api.allenneuraldynamics.org\"\n",
        "DATABASE = 'metadata_index'\n",
        "COLLECTION = 'data_assets'\n",
        "\n",
        "docdb_api_client = MetadataDbClient(\n",
        "   host=API_GATEWAY_HOST,\n",
        "   database=DATABASE,\n",
        "   collection=COLLECTION,\n",
        ")\n",
        "print(docdb_api_client._base_url)\n",
        "\n",
        "aggregate = [\n",
        "  {\n",
        "    \"$match\": {\n",
        "      \"session.session_type\": \"BCI single neuron stim\",\n",
        "      \"data_description.data_level\": \"derived\",\n",
        "      \"processing.processing_pipeline.data_processes.start_date_time\":{\"$gte\":\"2025-08-03\"}\n",
        "    }\n",
        "  },\n",
        "  {\n",
        "    \"$project\": {\n",
        "      \"name\": 1,\n",
        "      \"subject_id\": \"$data_description.subject_id\",\n",
        "      \"genotype\": \"$subject.genotype\",\n",
        "      \"virus\": \"$procedures.subject_procedures.procedures.injection_materials.name\",\n",
        "      \"date_of_birth\": \"$subject.date_of_birth\",\n",
        "      \"sex\": \"$subject.sex\",\n",
        "      \"session_type\": \"$session.session_type\",\n",
        "      \"session_time\": \"$session.session_start_time\",\n",
        "      \"stimulus_epochs\": \"$session.stimulus_epochs.stimulus_name\",\n",
        "      \"project_name\": \"$data_description.project_name\",\n",
        "      \"modality\": \"$data_description.modality.name\",\n",
        "      \"targeted_structure\": \"$session.data_streams.stack_parameters.targeted_structure\",\n",
        "      \"session_number\": {\n",
        "        \"$filter\": {\n",
        "          \"input\": \"$session.stimulus_epochs\",\n",
        "          \"as\": \"epoch\",\n",
        "          \"cond\": { \"$eq\": [\"$$epoch.stimulus_name\", \"single neuron BCI conditioning\"] }\n",
        "        }\n",
        "      },\n",
        "      \"ophys_fov\": {\n",
        "            '$map': {\n",
        "                'input': '$session.data_streams',\n",
        "                'as': 'stream',\n",
        "                'in': {\n",
        "                    '$map': {\n",
        "                            'input': '$$stream.ophys_fovs',\n",
        "                            'as': 'fov',\n",
        "                            'in': '$$fov.notes'\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "     \"magnification\": \"$session.data_streams.stack_parameters.magnification\",\n",
        "    }\n",
        "  },\n",
        "  {\n",
        "    \"$project\": {\n",
        "      \"name\": 1,\n",
        "      \"subject_id\": 1,\n",
        "      \"genotype\": 1,\n",
        "      \"virus\": 1,\n",
        "      \"date_of_birth\": 1,\n",
        "      \"sex\": 1,\n",
        "      \"session_type\": 1,\n",
        "      \"session_time\": 1,\n",
        "      \"stimulus_epochs\": 1,\n",
        "      \"project_name\": 1,\n",
        "      \"modality\": 1,\n",
        "      \"targeted_structure\": 1,\n",
        "      \"session_number\": { \"$arrayElemAt\": [\"$session_number.session_number\", 0] },\n",
        "      \"ophys_fov\": 1,\n",
        "      \"magnification\": 1\n",
        "    }\n",
        "  },\n",
        "  {'$unwind': {'path': '$ophys_fov', 'preserveNullAndEmptyArrays': False}},\n",
        "  {'$unwind': {'path': '$ophys_fov', 'preserveNullAndEmptyArrays': False}},\n",
        "  {'$unwind': {'path': '$virus', 'preserveNullAndEmptyArrays': False}},\n",
        "  {'$unwind': {'path': '$virus', 'preserveNullAndEmptyArrays': False}},\n",
        "  {'$unwind': {'path': '$virus', 'preserveNullAndEmptyArrays': False}},\n",
        "  {'$unwind': {'path': '$modality', 'preserveNullAndEmptyArrays': False}},\n",
        "  {'$unwind': {'path': '$targeted_structure', 'preserveNullAndEmptyArrays': False}},\n",
        "  {'$unwind': {'path': '$magnification', 'preserveNullAndEmptyArrays': False}}\n",
        "\n",
        "]\n",
        "\n",
        "records = docdb_api_client.aggregate_docdb_records(\n",
        "    pipeline = aggregate,\n",
        ")\n",
        "\n",
        "\n",
        "metadata = pd.DataFrame(records)\n",
        "metadata = metadata.drop_duplicates(subset=\"name\")\n",
        "\n",
        "metadata['session_date'] = metadata.apply(lambda x: datetime.fromisoformat(x['session_time']).date(), axis=1)\n",
        "metadata['session_time'] = metadata.apply(lambda x: datetime.fromisoformat(x['session_time']).time(), axis=1)\n",
        "metadata['date_of_birth'] = metadata.apply(lambda x: datetime.strptime(x['date_of_birth'], '%Y-%m-%d').date(), axis=1)\n",
        "metadata['age'] = metadata.apply(lambda x: (x['session_date'] - x['date_of_birth']).days, axis=1)\n",
        "\n",
        "order = ['project_name','session_type','_id','name','subject_id','genotype','virus','date_of_birth',\\\n",
        "         'sex','modality','session_date','age','session_time','targeted_structure','ophys_fov','session_number']\n",
        "metadata = metadata[order]\n",
        "metadata\n",
        "\n",
        "# 08/24/25 fix - Remove problem metadata rows\n",
        "problem_assets = [\n",
        "    \"single-plane-ophys_731015_2025-01-28_17-40-57_processed_2025-08-04_04-38-08\",\n",
        "    \"single-plane-ophys_772414_2025-02-04_13-21-29_processed_2025-08-12_06-14-42\"\n",
        "]\n",
        "\n",
        "metadata = metadata[~metadata[\"name\"].isin(problem_assets)]\n",
        "\n",
        "print('Successfully imported metadata from DocDB')"
      ],
      "metadata": {
        "id": "ROg73M1sEjmx",
        "cellView": "form"
      },
      "id": "ROg73M1sEjmx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a2ab7c1a-ce38-4e8e-9aa8-061bbad66fa9",
      "metadata": {
        "id": "a2ab7c1a-ce38-4e8e-9aa8-061bbad66fa9"
      },
      "source": [
        "# **Metadata Overview**\n",
        "\n",
        "Let's look at the metadata dataframe. Below are full descriptions for the columns in the metadata dataframe.\n",
        "\n",
        "| Column    | Description |\n",
        "| -------- | ------- |\n",
        "| id | data asset id |\n",
        "| name | filename of data asset (raw) |\n",
        "| subject_id| numerical id for animal subject  |\n",
        "| session_time |  experiment date (%Y-%m-%d %H:%M:%S)   |\n",
        "| session_type   |  experiment identifier  |\n",
        "| genotype  | subject genotype   |\n",
        "| virus   | injected virus type  |\n",
        "| ophys_fov   | field of view identifier  |\n",
        "| session_number    | behavior training session number (days)   |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58b44a04-7662-4bbc-8140-fc4bd277ed72",
      "metadata": {
        "id": "58b44a04-7662-4bbc-8140-fc4bd277ed72"
      },
      "outputs": [],
      "source": [
        "metadata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad2cb87-12a3-452c-99bf-7b0bd2987b42",
      "metadata": {
        "id": "1ad2cb87-12a3-452c-99bf-7b0bd2987b42"
      },
      "outputs": [],
      "source": [
        "metadata.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pandas Basics**\n",
        "\n",
        "Pandas DataFrames are 2 dimensional tables with columns and rows, similar to an Excel spreadsheet.\n",
        "\n",
        "We can access a specific column using dot notation."
      ],
      "metadata": {
        "id": "LTpxxldNhq-V"
      },
      "id": "LTpxxldNhq-V"
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.name"
      ],
      "metadata": {
        "id": "LKlIrrqdiX0h"
      },
      "id": "LKlIrrqdiX0h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use square brackets with the string of the column name inside, like this. (Also, we can add .head() at the end to show just the top 5 rows)"
      ],
      "metadata": {
        "id": "XG7Uk79aibj0"
      },
      "id": "XG7Uk79aibj0"
    },
    {
      "cell_type": "code",
      "source": [
        "metadata['name'].head()"
      ],
      "metadata": {
        "id": "wn_N2Nu9iQhz"
      },
      "id": "wn_N2Nu9iQhz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access data for a specific row, use .iloc and an index number or a range of index numbers."
      ],
      "metadata": {
        "id": "R3j-cCaHijng"
      },
      "id": "R3j-cCaHijng"
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.iloc[0]"
      ],
      "metadata": {
        "id": "V-TqukEXjB5u"
      },
      "id": "V-TqukEXjB5u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can select for a particular column AND rows to slice the metadata in particular ways"
      ],
      "metadata": {
        "id": "F2RYS1V2jE8J"
      },
      "id": "F2RYS1V2jE8J"
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.name.iloc[0:10]"
      ],
      "metadata": {
        "id": "SenncxJ7jLYm"
      },
      "id": "SenncxJ7jLYm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use operations to filter data for specific conditions. For example, let's say I only want to look at data for subjects >200 days old.  \n",
        "\n",
        "First, I take the DataFrame, then add square brackets with my conditional statement to filter that DataFrame. I use dot notation to only return the age column."
      ],
      "metadata": {
        "id": "9gV32uwPlB-T"
      },
      "id": "9gV32uwPlB-T"
    },
    {
      "cell_type": "code",
      "source": [
        "metadata[metadata.age >= 200].age"
      ],
      "metadata": {
        "id": "2azCSNM6lJmw"
      },
      "id": "2azCSNM6lJmw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding `.values` to the end of your code will extract only the raw data, like so:"
      ],
      "metadata": {
        "id": "l6p5Kc9iji2x"
      },
      "id": "l6p5Kc9iji2x"
    },
    {
      "cell_type": "code",
      "source": [
        "metadata[metadata.age >= 200].age.values"
      ],
      "metadata": {
        "id": "lDBXI7RujeOf"
      },
      "id": "lDBXI7RujeOf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas Resources\n",
        "\n",
        "For more information on pandas operations, refer to the Pandas [documentation](https://pandas.pydata.org/docs/user_guide/10min.html) or this [Pandas cheatsheet](https://drive.google.com/file/d/1umRjn86wiV_zMqt_oW6BSncmsHXvfDq3/view)"
      ],
      "metadata": {
        "id": "N2dszw7Og8s8"
      },
      "id": "N2dszw7Og8s8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **What can we learn from the Metadata DataFrame?**\n",
        "\n",
        "In addition to calling specific columns and rows to get specific information from the dataframe, we can apply useful Python and Pandas functions to quantify the data we extracted. We can answer questions like:\n",
        "\n",
        "What unique brain regions were recorded from in this dataset?"
      ],
      "metadata": {
        "id": "1Xwdj3dWiK65"
      },
      "id": "1Xwdj3dWiK65"
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.targeted_structure.unique()"
      ],
      "metadata": {
        "id": "TPFTeTV5NoE-"
      },
      "id": "TPFTeTV5NoE-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or... What age ranges were used in this dataset?\n",
        "\n",
        "First, we can get just the age column of data. Then, we pass that column of data into the plt.hist function, which creates a histogram of the data.\n"
      ],
      "metadata": {
        "id": "r2tR1-CYkd_8"
      },
      "id": "r2tR1-CYkd_8"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(metadata.age)\n",
        "plt.xlabel('Age (days', fontsize = 18)\n",
        "plt.ylabel('Number of sessions', fontsize = 18)\n",
        "plt.title('Age distribution', fontsize = 18)"
      ],
      "metadata": {
        "id": "mavDqKWzkaHp"
      },
      "id": "mavDqKWzkaHp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fcd1b68c-cde4-4d64-be59-2e1f8bc75fe5",
      "metadata": {
        "id": "fcd1b68c-cde4-4d64-be59-2e1f8bc75fe5"
      },
      "source": [
        "Also... how many sessions were collected per mouse?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9fbdac-ad08-45bc-8a48-19ddd6a6292c",
      "metadata": {
        "id": "3a9fbdac-ad08-45bc-8a48-19ddd6a6292c"
      },
      "outputs": [],
      "source": [
        "metadata.subject_id.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What other information can you find using the metadata? How would you programmatically access and quantify that information?"
      ],
      "metadata": {
        "id": "H90TLHozjf85"
      },
      "id": "H90TLHozjf85"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "BXpmULoiVvEF"
      },
      "id": "BXpmULoiVvEF"
    },
    {
      "cell_type": "markdown",
      "id": "abd7df16-dfcd-4783-bb4d-910c4dd37ab1",
      "metadata": {
        "id": "abd7df16-dfcd-4783-bb4d-910c4dd37ab1"
      },
      "source": [
        "# **Select a session of interest**\n",
        "\n",
        "Using the metadata dataframe, let's select a mouse and session of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e74486-a70f-482e-8752-0090e2f9c4f3",
      "metadata": {
        "id": "08e74486-a70f-482e-8752-0090e2f9c4f3"
      },
      "outputs": [],
      "source": [
        "# # Pick a mouse\n",
        "subject_ids = np.sort(metadata['subject_id'].unique())\n",
        "subject_id = subject_ids[3]\n",
        "print('Selected subject_id is', subject_id)\n",
        "\n",
        "# Look at its metadata, sorted by 'session_number'\n",
        "this_mouse_metadata = metadata[metadata['subject_id']==subject_id].sort_values(by='session_number')\n",
        "this_mouse_metadata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04ead15-5de3-44b1-8e92-c25b04123c1a",
      "metadata": {
        "id": "a04ead15-5de3-44b1-8e92-c25b04123c1a"
      },
      "outputs": [],
      "source": [
        "# # Let's pick an example session for this mouse\n",
        "session_name = this_mouse_metadata.name.values[-1]\n",
        "print('Selected session is', session_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a073c0de",
      "metadata": {
        "id": "a073c0de"
      },
      "source": [
        "# **Load session data (NWB) from S3**\n",
        "    \n",
        "The data for each session is packaged into a Neurodata Without Borders (NWB) file and stored in a publicly accessible bucket on S3.\n",
        "\n",
        "We can access the data via S3 web link. The `get_s3_link` function below will construct the full S3 path link for a given `session_name`.\n",
        "\n",
        "The NWB files are packaged using a Zarr backend to compress the data for cloud-friendly storage. To load the files, we'll pass the full S3 link to the the [`NWBZarrIO`](https://pynwb.readthedocs.io/en/stable/tutorials/advanced_io/plot_zarr_io.html) package from `hdmf-zarr`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import get_s3_link function\n",
        "def get_s3_link(session_name):\n",
        "  \"\"\"\n",
        "  Finds the S3 link path that routes to the session data\n",
        "\n",
        "  Parameters:\n",
        "  session_name: str, name of session\n",
        "\n",
        "  Outputs:\n",
        "  s3_link: str, S3 link path\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # List top-level of the bucket\n",
        "  s3 = s3fs.S3FileSystem(anon=True)\n",
        "  files = s3.ls('aind-open-data')\n",
        "\n",
        "  # Get a specific data folder\n",
        "  root_path = 'aind-open-data/'\n",
        "  # construct full file path from aind-open-data + single-plane-ophys\n",
        "  prefix = root_path + session_name + '/'\n",
        "  experiment_files = s3.ls(prefix)\n",
        "  print(\"Experiment folder contents:\", experiment_files)\n",
        "\n",
        "  # Search experiment_files for something that contains 'nwb'\n",
        "  nwb_file = [f for f in experiment_files if \"nwb\" in f.lower()]\n",
        "  print(nwb_file)\n",
        "\n",
        "  full_s3_path = f's3://{nwb_file[0]}'\n",
        "  print(f\"Loading NWB file from: {full_s3_path}\")\n",
        "\n",
        "  return full_s3_path\n"
      ],
      "metadata": {
        "id": "VgRk2ZsU90jP",
        "cellView": "form"
      },
      "id": "VgRk2ZsU90jP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_s3_path = get_s3_link(session_name)\n",
        "\n",
        "# Load NWB File using NWBZarrIO\n",
        "io = NWBZarrIO(path=full_s3_path, mode='r', storage_options={'anon': True})\n",
        "nwbfile = io.read()"
      ],
      "metadata": {
        "id": "VuQEc1l_-Uwy"
      },
      "id": "VuQEc1l_-Uwy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a124451f-967d-4470-8a38-dfd895353390",
      "metadata": {
        "id": "a124451f-967d-4470-8a38-dfd895353390"
      },
      "source": [
        "# **Neurodata Without Borders (NWB) Overview**\n",
        "\n",
        "NWB files are a standardized file format for systems neuroscience experiments. They are formatted similarly to hdf5 containers, with data stored in a hierarchical format made up of distinct containers.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nwbfile"
      ],
      "metadata": {
        "id": "IftRG0u42tNN"
      },
      "id": "IftRG0u42tNN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "l-vQIIGOVyJ4"
      },
      "id": "l-vQIIGOVyJ4"
    },
    {
      "cell_type": "markdown",
      "id": "5d20c891-fa7a-4e4d-b75f-1df85d0d1cab",
      "metadata": {
        "id": "5d20c891-fa7a-4e4d-b75f-1df85d0d1cab"
      },
      "source": [
        "# **What data is available? How was it processed?**\n",
        "\n",
        "The data packaged in the NWB file has been **processed**. What does this entail?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Raw data**\n",
        "\n",
        "During each recording session, videos were collected from the 2-photon microscope which captured changes in fluorescent activity from a population of neurons in primary motor cortex. Using genetic labelling strategies, neurons expressed GCaMP, a genetically encoded calcium indicator which causes neurons to fluoresce when calcium levels rise in the cell. The fluorescent signal can be used as a readout of neuron activity.\n",
        "\n",
        "While the NWB file does not contain the raw video itself, we can see the average projection of all the frames in the video for this session."
      ],
      "metadata": {
        "id": "zS54hMzHKTpl"
      },
      "id": "zS54hMzHKTpl"
    },
    {
      "cell_type": "code",
      "source": [
        "average_image = nwbfile.processing[\"processed\"].data_interfaces[\"images\"].images[\"average_projection\"].data[:]\n",
        "\n",
        "# Plot average projection of images\n",
        "\n",
        "# Set up figure\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "# Use imshow to plot the image\n",
        "plt.imshow(average_image, cmap='gray', origin='upper', aspect='equal', vmax=0.25)\n",
        "plt.title('Average Projection of Field of View')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "5CW6UBid4y5w"
      },
      "id": "5CW6UBid4y5w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Image Segmentation**\n",
        "\n",
        "In the average projection image, notice that there are hundreds of dim to bright, round circles. These are the somas of the neurons, which we use to read out neuron activity based on changes in fluorescence.\n",
        "\n",
        "As part of processing, the videos are run through software like Suite2p or CellPose, which use machine learning to segment regions of interest (ROIs) that likely correspond to the somas. This process is called image segmentation.\n",
        "\n",
        "The extracted ROIs (the outputs of Suite2p/CellPose) are represented as image masks, a HxW sparse array with non-zero values that define the spatial boundaries and intensity profiles of the ROIs. That data is contained in the **processed > processing > image segmentation > plane segmentations** container.\n",
        "\n",
        "We'll load just the image masks for now and overlay with the average projection image."
      ],
      "metadata": {
        "id": "W7w9UHS75mrD"
      },
      "id": "W7w9UHS75mrD"
    },
    {
      "cell_type": "code",
      "source": [
        "image_masks = nwbfile.processing[\"processed\"].data_interfaces['image_segmentation'].plane_segmentations['roi_table'][:].image_mask\n",
        "image_masks\n",
        "\n",
        "# every row is an ROI"
      ],
      "metadata": {
        "id": "m_g8eY1G65lV"
      },
      "id": "m_g8eY1G65lV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROI contours overlayed on average image\n",
        "\n",
        "# Set up figure\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "# Plot average image\n",
        "plt.imshow(average_image, cmap='gray', origin='upper', aspect='equal', vmax=0.25)\n",
        "plt.title('ROI Contours Overlaid on Average Projection for Valid ROIs')\n",
        "plt.axis('off')\n",
        "\n",
        "# Overlay ROI contours\n",
        "for mask in image_masks:\n",
        "  mask_array = np.array(mask)\n",
        "  # Find contours at a level that works well for binary masks\n",
        "  contours = measure.find_contours(mask_array, level=0.5)\n",
        "\n",
        "  for contour in contours:\n",
        "    color = 'yellow'\n",
        "    linewidth = 0.5\n",
        "\n",
        "    # Plot contour (note: contour coordinates are in (row, col) format)\n",
        "    plt.plot(contour[:, 1], contour[:, 0], color=color, linewidth=linewidth)\n",
        "\n",
        "# Set the axis limits to match the image dimensions\n",
        "plt.xlim(0, average_image.shape[1])\n",
        "plt.ylim(average_image.shape[0], 0)  # Flip y-axis to match image coordinates\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5xd8H8ni5e_v"
      },
      "id": "5xd8H8ni5e_v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Cell classification**\n",
        "\n",
        "Notice that there are 1000s of ROIs in this image. Not all of them look like somas. Depending on the parameters used in data processing (and the data itself), Suite2p/CellPose can pick up a lot of ROIs or just a few. After image segmentation, our processing pipeline evaluates the ROIs to determine the likelihood that they are somas or something else, like a dendrite or vessel.\n",
        "\n",
        "The function below will filter out ROIs that are not somas and return a table with just the clean ROIs (and ensures that any experimentally relevant neurons are included)."
      ],
      "metadata": {
        "id": "LZyVIsT0-Y2C"
      },
      "id": "LZyVIsT0-Y2C"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import soma filtering function\n",
        "def filter_roi_table(nwbfile) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "  nwbfile: NWBFile object\n",
        "\n",
        "  Outputs:\n",
        "  filtered_roi_table: pandas DataFrame, filtered ROI table with only ROIs that pass soma classifier and photostimulated and conditioned neurons\n",
        "  \"\"\"\n",
        "  # Get photostim and cn indices from tables in NWB file\n",
        "  photostim_ids = nwbfile.stimulus[\"PhotostimTrials\"].to_dataframe().closest_roi.values\n",
        "  cn_id = nwbfile.stimulus[\"Trials\"].to_dataframe().closest_roi.values\n",
        "  roi_table = nwbfile.processing[\"processed\"].data_interfaces[\"image_segmentation\"].plane_segmentations[\"roi_table\"][:]\n",
        "\n",
        "  missing_ids = np.unique(np.concatenate([photostim_ids, cn_id]))\n",
        "\n",
        "  # Check which indices did not pass soma detection\n",
        "  add_ids = []\n",
        "  for idx in missing_ids:\n",
        "    if roi_table.iloc[idx].is_soma == 0:\n",
        "      add_ids.append(idx)\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  # Filter roi table for those that pass is_soma and for indices of missing ids\n",
        "  filtered_roi_table = roi_table[roi_table.is_soma==1]\n",
        "  # to filtered_roi_table add in indices from roi table that correspond to missing ids\n",
        "  filtered_roi_table = pd.concat(\n",
        "    [filtered_roi_table, roi_table.iloc[add_ids]],\n",
        "    ignore_index=False  # reindex rows if you don’t care about preserving original indices\n",
        "  )\n",
        "\n",
        "  filtered_roi_table = filtered_roi_table[['image_mask']]\n",
        "\n",
        "  return filtered_roi_table"
      ],
      "metadata": {
        "id": "X8IfphPZrPLW",
        "cellView": "form"
      },
      "id": "X8IfphPZrPLW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d8ecda98-5fca-4d4d-ba32-58f042df2a29",
      "metadata": {
        "id": "d8ecda98-5fca-4d4d-ba32-58f042df2a29"
      },
      "source": [
        "Here is a description of the columns in the ROI table (filtered_roi_table):\n",
        "\n",
        "| Column    | Description |\n",
        "| -------- | ------- |\n",
        "| id | index in dff array that corresponds to the ROI |\n",
        "| image_mask  | HxW sparse array defining image masks|"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_roi_table = filter_roi_table(nwbfile)\n",
        "filtered_roi_table"
      ],
      "metadata": {
        "id": "2AXm3TDWtCNC"
      },
      "id": "2AXm3TDWtCNC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's visually inspect only the ROIs that pass the soma classification we just ran."
      ],
      "metadata": {
        "id": "NlPEmRfiBBs2"
      },
      "id": "NlPEmRfiBBs2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROI contours overlayed on average image\n",
        "\n",
        "# Set up figure\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "# Plot average image\n",
        "plt.imshow(average_image, cmap='gray', origin='upper', aspect='equal', vmax=0.25)\n",
        "plt.title('ROI Contours Overlaid on Average Projection for Valid ROIs')\n",
        "plt.axis('off')\n",
        "\n",
        "# Overlay ROI contours\n",
        "for mask in filtered_roi_table.image_mask:\n",
        "  mask_array = np.array(mask)\n",
        "  # Find contours at a level that works well for binary masks\n",
        "  contours = measure.find_contours(mask_array, level=0.5)\n",
        "\n",
        "  for contour in contours:\n",
        "    color = 'yellow'\n",
        "    linewidth = 0.5\n",
        "\n",
        "    # Plot contour (note: contour coordinates are in (row, col) format)\n",
        "    plt.plot(contour[:, 1], contour[:, 0], color=color, linewidth=linewidth)\n",
        "\n",
        "# Set the axis limits to match the image dimensions\n",
        "plt.xlim(0, average_image.shape[1])\n",
        "plt.ylim(average_image.shape[0], 0)  # Flip y-axis to match image coordinates\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tMbOqPUwA66l"
      },
      "id": "tMbOqPUwA66l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. DFF**\n",
        "\n",
        "For each ROI, the change in fluorescence (df) over a baseline (F) is calculated, resulting in the dff traces.\n",
        "\n",
        "First, the change in fluorescence within each ROI is calculated. Then, the signal is corrected for noise by subtracting the local neuropil signal. The corrected signal is then demixed from potentially overlapping ROIs. Finally, the corrected change in fluorescence signal is normalized over baseline fluorescence (median fluorescence over a 60s time window centered around each time point).\n",
        "\n",
        "The final \"dff\" data is stored in the **processing** container of the NWB file.\n",
        "\n",
        "Let's load 'dff', nframes x nrois array.\n"
      ],
      "metadata": {
        "id": "hhSLtIyRN3vg"
      },
      "id": "hhSLtIyRN3vg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2afce24-f8ad-4db7-bf22-1bd89c58c123",
      "metadata": {
        "id": "e2afce24-f8ad-4db7-bf22-1bd89c58c123"
      },
      "outputs": [],
      "source": [
        "dff_traces = nwbfile.processing[\"processed\"].data_interfaces[\"dff\"].roi_response_series[\"dff\"].data\n",
        "print('dff shape (nframes, nrois):',np.shape(dff_traces))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make an array for the timestamps for this trace using the `imaging_rate` - the rate at which the 2P frames were acquired"
      ],
      "metadata": {
        "id": "LEQx26okusYe"
      },
      "id": "LEQx26okusYe"
    },
    {
      "cell_type": "code",
      "source": [
        "#get imaging frame rate from the NWB file in Hz\n",
        "frame_rate = nwbfile.imaging_planes[\"processed\"].imaging_rate\n",
        "\n",
        "#convert to seconds\n",
        "time_step = 1/frame_rate\n",
        "\n",
        "#create equally spaced timestamps array\n",
        "n_frames = dff_traces.shape[0]\n",
        "timestamps = np.linspace(0, (time_step*n_frames), num=n_frames)"
      ],
      "metadata": {
        "id": "2u2IrzSHupLB"
      },
      "id": "2u2IrzSHupLB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot a neuron activity trace**\n",
        "Let's plot the dff trace over time for a select ROI. What do you notice about this neuron's activity?"
      ],
      "metadata": {
        "id": "tqSK_WZ4rvku"
      },
      "id": "tqSK_WZ4rvku"
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick an ROI\n",
        "ROI = 2221\n",
        "\n",
        "# Plot dff trace for selected ROI\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(timestamps, dff_traces[:, ROI], color='black')\n",
        "\n",
        "plt.ylabel('dF/F')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.title('dF/F for ROI '+str(ROI))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ixU1RRPGrmeK"
      },
      "id": "ixU1RRPGrmeK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise**\n",
        "\n",
        "Try selecting a different ROI and plotting the dff trace. How does the signal compare to the previous plot?"
      ],
      "metadata": {
        "id": "GOWPZ0iycqAN"
      },
      "id": "GOWPZ0iycqAN"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ihotsv4Kc0vW"
      },
      "id": "Ihotsv4Kc0vW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to show answer\n",
        "\n",
        "# Pick an ROI with a valid soma\n",
        "ROI = 5 # change the value here\n",
        "\n",
        "# Plot dff trace for selected ROI\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(timestamps, dff_traces[:, ROI], color='black')\n",
        "plt.ylabel('dF/F')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.title('dF/F for ROI '+str(ROI))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JsjLAAAvb-1Z"
      },
      "id": "JsjLAAAvb-1Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise**\n",
        "\n",
        "Try plotting dff over a narrower time window, say 100 seconds. Pick a region with interesting activity to inspect more closely."
      ],
      "metadata": {
        "id": "Xesw7MACdDQT"
      },
      "id": "Xesw7MACdDQT"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zEUeKscWdUrz"
      },
      "id": "zEUeKscWdUrz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to show answer\n",
        "# Pick an ROI with a valid soma\n",
        "ROI = 2221\n",
        "\n",
        "# Plot dff trace for selected ROI\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(timestamps, dff_traces[:, ROI], color='black')\n",
        "\n",
        "# Add xlim to plot a particular window of x\n",
        "plt.xlim(100, 200)\n",
        "plt.ylabel('dF/F')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.title('dF/F for ROI '+str(ROI))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9DmjakrFdT35"
      },
      "id": "9DmjakrFdT35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fbf59459-4d4f-42aa-833f-f9248c38a539",
      "metadata": {
        "id": "fbf59459-4d4f-42aa-833f-f9248c38a539"
      },
      "source": [
        "# **5. Epochs Table**\n",
        "\n",
        "DFF reports the continuous neural activity trace over the entire session. Let's add some context to the plot!\n",
        "\n",
        "The epochs table contains the start and stop times/frames for each experimental epoch. The start and stop frames can be used to index into the 2-photon timeseries, since they are temporally aligned.\n",
        "\n",
        "The epochs table is contained in the **intervals** container of the NWB file. The table is stored as a DynamicTable, which we convert to a Pandas DataFrame using `to_dataframe`, for better accessibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d8f132",
      "metadata": {
        "id": "c2d8f132"
      },
      "outputs": [],
      "source": [
        "# Load the epochs table from the NWB file\n",
        "epoch_table = nwbfile.intervals[\"epochs\"].to_dataframe()\n",
        "epoch_table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7ed8cd-2e87-4c6a-a3ff-177cc243fc89",
      "metadata": {
        "id": "8c7ed8cd-2e87-4c6a-a3ff-177cc243fc89"
      },
      "source": [
        "# **Plot neuron activity trace with epochs overlaid**\n",
        "\n",
        "Now plot the dF/F trace for the ROI we selected together above with the stimulus epochs overlaid in color. Does its activity change across epochs?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_table"
      ],
      "metadata": {
        "id": "X-xKSjbIktIv"
      },
      "id": "X-xKSjbIktIv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick an ROI\n",
        "ROI = 2221\n",
        "\n",
        "# Set up figure\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "# Plot dff trace\n",
        "plt.plot(timestamps, dff_traces[:, ROI], color=\"black\")\n",
        "\n",
        "# Get epoch info\n",
        "epoch_table = nwbfile.intervals[\"epochs\"].to_dataframe()\n",
        "stimulus_names = epoch_table.stimulus_name.unique()\n",
        "\n",
        "# Define fixed colors\n",
        "color_map = {\n",
        "    \"spont\": \"orange\",\n",
        "    \"photostim\": \"purple\",\n",
        "    \"other\": \"green\"\n",
        "}\n",
        "\n",
        "# Plot shaded blocks for each stimulus epoch\n",
        "for stimulus_name in stimulus_names:\n",
        "    stim_epoch = epoch_table[epoch_table.stimulus_name == stimulus_name]\n",
        "\n",
        "    # Assign color based on name\n",
        "    lname = stimulus_name.lower()\n",
        "    if \"spont\" in lname:\n",
        "        color = color_map[\"spont\"] # All spontaneous epochs == orange\n",
        "    elif \"photostim\" in lname:\n",
        "        color = color_map[\"photostim\"] # All photostim epochs == purple\n",
        "    else:\n",
        "        color = color_map[\"other\"] # Other (BCI) == green\n",
        "\n",
        "    plt.axvspan(stim_epoch.start_time.values[0], stim_epoch.stop_time.values[0], color=color, alpha=0.3, label=stimulus_name)\n",
        "\n",
        "# Labels and title\n",
        "plt.ylabel(\"dF/F\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.title(f\"Stimulus epochs and dF/F for ROI {ROI}\")\n",
        "plt.legend(bbox_to_anchor=(1.0, 1.0))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3-CcsyWQeWny"
      },
      "id": "3-CcsyWQeWny",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Discuss**\n",
        "\n",
        "Referring back to the previous exercise where you zoomed in on a section of the dff trace, what epoch does this section fall into? What was happening during the experiment that could explain the dynamics of the signal?"
      ],
      "metadata": {
        "id": "qEeKe08Ahc2J"
      },
      "id": "qEeKe08Ahc2J"
    },
    {
      "cell_type": "markdown",
      "id": "109c2911-1374-481d-a2e1-edabafcd18f9",
      "metadata": {
        "id": "109c2911-1374-481d-a2e1-edabafcd18f9"
      },
      "source": [
        "# **6. Trials tables**\n",
        "\n",
        "The trials tables tells you what happened in each epoch on a trial-by-trial basis. These tables are found in the **stimulus** container of the NWB file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a8c15e4-7459-4957-80df-cccbd2b99ab6",
      "metadata": {
        "id": "5a8c15e4-7459-4957-80df-cccbd2b99ab6"
      },
      "outputs": [],
      "source": [
        "# These are the available stimulus tables\n",
        "nwbfile.stimulus.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e6d58fa-8213-4cb0-bd3b-3aa074b938e4",
      "metadata": {
        "id": "2e6d58fa-8213-4cb0-bd3b-3aa074b938e4"
      },
      "source": [
        "# **6a. Trials tables: optogenetic photostimulation trials**\n",
        "    \n",
        "The `PhotostimTrials` table contains information about each 2p optogenetic stimulation trial. Optogenetic stimulation is used in this experiment to probe connectivity between neurons. In each trial, one neuron is stimulated, and all other neurons are recorded. Neurons with short latency responses after the optostim can be considered to be causally connected.\n",
        "    \n",
        "Below is a decription for each of the columns in the photostim trials table:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed8ea67-53a2-4fa7-a46c-fd8e9f13f799",
      "metadata": {
        "id": "3ed8ea67-53a2-4fa7-a46c-fd8e9f13f799"
      },
      "source": [
        "| Column    | Description |\n",
        "| -------- | ------- |\n",
        "| start_time  | stimulus start (s)  |\n",
        "| stop_time | stimulus end (s)   |\n",
        "| start_frame | stimulus start (frame)     |\n",
        "| stop_frame    | stimulus end (frame)  |\n",
        "| tiff_file   | data source file name  |\n",
        "| stimulus_name    | stimulus name   |\n",
        "| laser_x    | x coordinate of stimulated neuron (pixel)   |\n",
        "| laser_y    | y coordinate of stimulated neuron (pixel)  |\n",
        "| power    | stimulus intensity (mW)  |\n",
        "| duration    | trial duration (s)  |\n",
        "| stimulus_function    | stimulus template   |\n",
        "| group_index    | identity of stimulated neuron(s)   |\n",
        "| closest_roi    | index in dff that corresponds to the photostimulated neuron   |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f30a8931-759b-470b-b5bb-eb35ce80e9df",
      "metadata": {
        "id": "f30a8931-759b-470b-b5bb-eb35ce80e9df"
      },
      "outputs": [],
      "source": [
        "photostim = nwbfile.stimulus[\"PhotostimTrials\"].to_dataframe()\n",
        "photostim.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d3d000-41d3-4652-b3e9-8d8cd5b9efcf",
      "metadata": {
        "id": "57d3d000-41d3-4652-b3e9-8d8cd5b9efcf"
      },
      "source": [
        "\n",
        "# **Exercise:** Check the unique values of the `stimulus_name` column of the `PhotostimTrials` table.\n",
        "\n",
        "Do they correspond to the stimulus names in the `epoch_table`?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-u1a388PTBco"
      },
      "id": "-u1a388PTBco",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzGfFG3jTC4f"
      },
      "id": "dzGfFG3jTC4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6cd1284-6cbd-432d-a126-224166bec64b",
      "metadata": {
        "id": "d6cd1284-6cbd-432d-a126-224166bec64b",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Click to show answer\n",
        "# Stimuli in photostim trials table\n",
        "photostim['stimulus_name'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11920753-3bc8-4777-915e-e5b6ba3ffaf3",
      "metadata": {
        "id": "11920753-3bc8-4777-915e-e5b6ba3ffaf3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Click to show answer\n",
        "# Compare to epochs\n",
        "epoch_table.stimulus_name.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fefb390b",
      "metadata": {
        "id": "fefb390b"
      },
      "source": [
        "# **6b. Trials tables: BCI behavior trials**\n",
        "    \n",
        "The behavior trials table contains information about what the mouse did during each trial, such as whether it licked or got a reward, and when in the trial these events happened. It also includes the ID of the conditioned neuron.\n",
        "    \n",
        "Here is a description of the columns of this table:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "174dfa4b-577b-4bcf-afcd-e57f1671abdc",
      "metadata": {
        "id": "174dfa4b-577b-4bcf-afcd-e57f1671abdc"
      },
      "source": [
        "| Column    | Description |\n",
        "| -------- | ------- |\n",
        "| start_time  | trial start (s)  |\n",
        "| stop_time | trial end (s)   |\n",
        "| go_cue |  time of go cue relative to start time (s)   |\n",
        "| hit   |  boolean of whether trial was hit   |\n",
        "| lick_l  | lick times (s)   |\n",
        "| reward_time   | reward delivery time (s)   |\n",
        "| threshold_crossing_times    | time when reward port crossed position threshold (s)   |\n",
        "| zaber_steps_times   | times when reward port moves  |\n",
        "| tiff_file    | data source file name  |\n",
        "| start_frame    | trial start (frame)  |\n",
        "| stop_frame    | trial end (frame)  |\n",
        "| conditioned_neuron_x    | coordinate for conditioned neuron (pixels)  |\n",
        "| conditioned_neuron_y    | coordinate for conditioned neuron (pixels)  |\n",
        "| closest_roi    | index in dff that corresponds to the conditioned neuron  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c2d9dc-9f4d-4aae-886c-de698e276e9d",
      "metadata": {
        "id": "15c2d9dc-9f4d-4aae-886c-de698e276e9d"
      },
      "source": [
        "# **Exercise:** Load the `Trials` table from the *<b>stimulus</b>* container, turn it into a dataframe called trials.\n",
        "    \n",
        "What happens during the BCI task epoch? What information is provided for each trial?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JmZuB8FNTFep"
      },
      "id": "JmZuB8FNTFep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "335544fe-c236-40ac-8e22-ab84886fcd1f",
      "metadata": {
        "id": "335544fe-c236-40ac-8e22-ab84886fcd1f"
      },
      "outputs": [],
      "source": [
        "# @title Click to show anwer\n",
        "\n",
        "# Load the BCI trials table\n",
        "trials = nwbfile.stimulus[\"Trials\"].to_dataframe()\n",
        "trials.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6dca8f7-6067-4993-ba09-5816e7eca5b3",
      "metadata": {
        "id": "f6dca8f7-6067-4993-ba09-5816e7eca5b3"
      },
      "outputs": [],
      "source": [
        "# What info do we have for each trial?\n",
        "trials.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf1cc459-cc6e-4b88-b177-03d5722602a7",
      "metadata": {
        "id": "cf1cc459-cc6e-4b88-b177-03d5722602a7"
      },
      "source": [
        "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
        "\n",
        "What is the ROI ID of the conditioned neuron?\n",
        "\n",
        "This ID refers to the index in the dff array that corresponds to the conditioned neuron.\n",
        "        \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57a04d86-8fa3-457f-b5f8-0875cee85e3a",
      "metadata": {
        "id": "57a04d86-8fa3-457f-b5f8-0875cee85e3a"
      },
      "outputs": [],
      "source": [
        "# The conditioned neuron ID is indicated by the 'closest_roi' column\n",
        "trials.closest_roi.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise**\n",
        "\n",
        "Plot the dff trace of the conditioned neuron during the BCI epoch.\n",
        "\n"
      ],
      "metadata": {
        "id": "yU3u0j4Nqmig"
      },
      "id": "yU3u0j4Nqmig"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0b0KCzYErixd"
      },
      "id": "0b0KCzYErixd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to show answer\n",
        "# Get the roi id for the conditioned neuron\n",
        "ROI = trials.closest_roi.unique()\n",
        "\n",
        "# Get time window for BCI epoch\n",
        "start_f = epoch_table[epoch_table.stimulus_name == \"BCI\"].start_time.iloc[0]\n",
        "stop_f = epoch_table[epoch_table.stimulus_name == \"BCI\"].stop_time.iloc[0]\n",
        "\n",
        "# Plot dff trace for selected ROI\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(timestamps, dff_traces[:, ROI], color='black')\n",
        "\n",
        "# Plot only defined time window\n",
        "plt.xlim(start_f, stop_f)\n",
        "\n",
        "plt.ylabel('dF/F')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.title('dF/F for Conditioned Neuron During BCI Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XJAH1hirqOSR",
        "cellView": "form"
      },
      "id": "XJAH1hirqOSR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot Conditioned Neuron activity aligned with behavior events**\n",
        "\n",
        "The activity of a single neuron is used to control the movement of a lick port (actuated by a zaber motor) towards the mouse's face. Let's take a look at the activity of the conditioned neuron relative to some of the behavior events described in the \"trials\" table from before.\n",
        "\n",
        "We'll plot the trial start (start_time), when the lickport moved (zaber_step_times), and the reward times (reward_time). Note that units for the zaber_step_times and reward_time is in seconds and is reported relative to the start of the trial."
      ],
      "metadata": {
        "id": "UPBdHsE4cN7J"
      },
      "id": "UPBdHsE4cN7J"
    },
    {
      "cell_type": "code",
      "source": [
        "trials.head()"
      ],
      "metadata": {
        "id": "d2RsQrzIwvV8"
      },
      "id": "d2RsQrzIwvV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For plotting, let's build a list of all the times for each behavioral event.\n",
        "\n",
        "For each trial, we need to get the event times for a given behavioral event and add the start_time of that trial to it."
      ],
      "metadata": {
        "id": "kn5_5D66dMte"
      },
      "id": "kn5_5D66dMte"
    },
    {
      "cell_type": "code",
      "source": [
        "#create empty lists for the behavior events\n",
        "lick_times = []\n",
        "go_cues = []\n",
        "rewards = []\n",
        "threshold_crossing_times = []\n",
        "zaber_step_times = []\n",
        "\n",
        "#for each trial, add the event times to trial start and append to appropriate list\n",
        "for index, row in trials.iterrows():\n",
        "    lick_times.append(row.lick_L[np.isfinite(row.lick_L)] + row.start_time) # use isfinite to filter out nans\n",
        "    zaber_step_times.append(row.zaber_step_times[np.isfinite(row.zaber_step_times)] + row.start_time)\n",
        "    go_cues.append(row.go_cue + row.start_time)\n",
        "    rewards.append(row.reward_time + row.start_time)\n",
        "    threshold_crossing_times.append(row.threshold_crossing_times + row.start_time)\n",
        "\n",
        "#reshape lick_times and zaber_step_times (this is needed because there is a list of times for each trial)\n",
        "lick_times = np.hstack(lick_times)\n",
        "zaber_step_times = np.hstack(zaber_step_times)"
      ],
      "metadata": {
        "id": "wZrQdLO47ea3"
      },
      "id": "wZrQdLO47ea3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot all of the reward times. We can use `np.ones_like` to make an array of 1s the length of the number of values in the rewards list."
      ],
      "metadata": {
        "id": "pcsBRrFZxXDg"
      },
      "id": "pcsBRrFZxXDg"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(rewards, np.ones_like(rewards), '|')\n",
        "\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.title(\"Reward times\")"
      ],
      "metadata": {
        "id": "A6xMU8jZxLk1"
      },
      "id": "A6xMU8jZxLk1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the behavior events in absolute time, let's plot both the dff trace of the conditioned neuron and the behavior events."
      ],
      "metadata": {
        "id": "CxmTrBkNfasx"
      },
      "id": "CxmTrBkNfasx"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "#plot the dff of the conditioned neuron\n",
        "plt.plot(timestamps, dff_traces[:, ROI], color='gray', alpha = 0.6)\n",
        "\n",
        "#plot the lick times, rewards, trial start times, and zaber steps\n",
        "plt.plot(lick_times, np.ones_like(lick_times), 'g.', label=\"Licks\")\n",
        "plt.plot(rewards, np.ones_like(rewards), 'ro', label=\"Rewards\")\n",
        "#we'll put the zaber steps a little higher on the plot by multiplying the y-values by 2\n",
        "plt.plot(zaber_step_times, np.ones_like(zaber_step_times)*2, '|', label=\"Zaber steps\")\n",
        "# plot the trial start times\n",
        "plt.plot(trials.start_time.values, np.ones_like(trials.start_time.values), 'bo',linewidth = 5, label = \"Trial start\")\n",
        "\n",
        "#add a legend\n",
        "plt.legend()\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"dF/F\")\n",
        "\n",
        "plt.xlim(1625,1700)\n",
        "plt.ylim(-1,4)"
      ],
      "metadata": {
        "id": "12ypIvRN7wc-"
      },
      "id": "12ypIvRN7wc-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "iN8LWDqBWsiY"
      },
      "id": "iN8LWDqBWsiY"
    },
    {
      "cell_type": "markdown",
      "id": "c1f09ea3-989f-4649-877b-7c1e976d25b7",
      "metadata": {
        "id": "c1f09ea3-989f-4649-877b-7c1e976d25b7"
      },
      "source": [
        "\n",
        "# **How does neural activity change with learning?**\n",
        "\n",
        "Now that we've walked through how to load the NWB file and extract the main data pieces. Let's go back to our original question - could the learning that happens during the BCI task epoch change the activity of the other neurons in the imaging plane?\n",
        "\n",
        "\n",
        "How should we approach this question?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "\n",
        "# Assessing correlations in neural activity before and after learning!"
      ],
      "metadata": {
        "id": "DxNuUbeKo8sZ",
        "cellView": "form"
      },
      "id": "DxNuUbeKo8sZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h6oF5oNl4KrQ"
      },
      "id": "h6oF5oNl4KrQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z-FDB65o4LtS"
      },
      "id": "z-FDB65o4LtS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bgA1zmDp4LPw"
      },
      "id": "bgA1zmDp4LPw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlations**\n",
        "\n",
        "Correlation coefficients are commonly used to evaluate if there's a linear relationship between two variables, or in this case, two neurons. Here, we will use Pearson Correlation, which is computed using the formula:\n",
        "\n",
        "\n",
        "\n",
        "![correlation_coefficient_formula.svg](data:image/svg+xml;base64,<svg xlink="http://www.w3.org/1999/xlink" width="54.695ex" height="13.383ex" viewBox="0 -2595.7 23549.3 5762" role="img" focusable="false" style="vertical-align: -7.354ex;" aria-hidden="true" xmlns="http://www.w3.org/2000/svg"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use transform="scale(1.73)" href="#MJMATHI-72" x="0" y="0"><path stroke-width="10" id="MJMATHI-72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></use><use transform="scale(1.73)" href="#MJMAIN-3D" x="733" y="0"><path stroke-width="10" id="MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></use><g transform="translate(2624,0)"><g transform="translate(688,0)"><rect stroke="none" width="20029" height="103" x="0" y="380"></rect><g transform="translate(2825,1176)"><use transform="scale(1.73)" href="#MJSZ1-2211" x="0" y="0"><path stroke-width="10" id="MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></use><g transform="translate(2123,0)"><use transform="scale(1.73)" href="#MJMAIN-28" x="0" y="0"><path stroke-width="10" id="MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></use><g transform="translate(681,0)"><use transform="scale(1.73)" href="#MJMATHI-78" x="0" y="0"><path stroke-width="10" id="MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></use><use transform="scale(1.223)" href="#MJMATHI-69" x="816" y="-213"><path stroke-width="10" id="MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></use></g><use transform="scale(1.73)" href="#MJMAIN-2212" x="1540" y="0"><path stroke-width="10" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></use><g transform="translate(4404,0)"><use transform="scale(1.73)" href="#MJMATHI-78" x="0" y="0"><path stroke-width="10" id="MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></use><use transform="scale(1.73)" href="#MJMAIN-AF" x="52" y="21"><path stroke-width="10" id="MJMAIN-AF" d="M69 544V590H430V544H69Z"></path></use></g><use transform="scale(1.73)" href="#MJMAIN-29" x="3122" y="0"><path stroke-width="10" id="MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></use></g><g transform="translate(8496,0)"><use transform="scale(1.73)" href="#MJMAIN-28"><path stroke-width="10" id="MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></use><g transform="translate(681,0)"><use transform="scale(1.73)" href="#MJMATHI-79" x="0" y="0"><path stroke-width="10" id="MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></use><use transform="scale(1.223)" href="#MJMATHI-69" x="700" y="-355"><path stroke-width="10" id="MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></use></g><use transform="scale(1.73)" href="#MJMAIN-2212" x="1458" y="0"><path stroke-width="10" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></use><g transform="translate(4262,0)"><use transform="scale(1.73)" href="#MJMATHI-79" x="1" y="0"><path stroke-width="10" id="MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></use><use transform="scale(1.73)" href="#MJMAIN-AF" x="36" y="22"><path stroke-width="10" id="MJMAIN-AF" d="M69 544V590H430V544H69Z"></path></use></g><use transform="scale(1.73)" href="#MJMAIN-29" x="3005" y="0"><path stroke-width="10" id="MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></use></g></g><g transform="translate(103,-2176)"><use transform="scale(1.73)" href="#MJSZ2-221A" x="0" y="122"><path stroke-width="10" id="MJSZ2-221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path></use><rect stroke="none" width="18083" height="103" x="1738" y="2114"></rect><g transform="translate(1738,0)"><use transform="scale(1.73)" href="#MJSZ1-2211" x="0" y="0"><path stroke-width="10" id="MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></use><g transform="translate(2123,0)"><use transform="scale(1.73)" href="#MJMAIN-28" x="0" y="0"><path stroke-width="10" id="MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></use><g transform="translate(681,0)"><use transform="scale(1.73)" href="#MJMATHI-78" x="0" y="0"><path stroke-width="10" id="MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></use><use transform="scale(1.223)" href="#MJMATHI-69" x="816" y="-213"><path stroke-width="10" id="MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></use></g><use transform="scale(1.73)" href="#MJMAIN-2212" x="1540" y="0"><path stroke-width="10" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></use><g transform="translate(4404,0)"><use transform="scale(1.73)" href="#MJMATHI-78" x="0" y="0"><path stroke-width="10" id="MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></use><use transform="scale(1.73)" href="#MJMAIN-AF" x="52" y="21"><path stroke-width="10" id="MJMAIN-AF" d="M69 544V590H430V544H69Z"></path></use></g><use transform="scale(1.73)" href="#MJMAIN-29" x="3122" y="0"><path stroke-width="10" id="MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></use><use transform="scale(1.223)" href="#MJMAIN-32" x="4973" y="688"><path stroke-width="10" id="MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></use></g><use transform="scale(1.73)" href="#MJSZ1-2211" x="5368" y="0"><path stroke-width="10" id="MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></use><g transform="translate(11411,0)"><use transform="scale(1.73)" href="#MJMAIN-28"><path stroke-width="10" id="MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></use><g transform="translate(681,0)"><use transform="scale(1.73)" href="#MJMATHI-79" x="0" y="0"><path stroke-width="10" id="MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></use><use transform="scale(1.223)" href="#MJMATHI-69" x="700" y="-355"><path stroke-width="10" id="MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></use></g><use transform="scale(1.73)" href="#MJMAIN-2212" x="1458" y="0"><path stroke-width="10" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></use><g transform="translate(4262,0)"><use transform="scale(1.73)" href="#MJMATHI-79" x="1" y="0"><path stroke-width="10" id="MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></use><use transform="scale(1.73)" href="#MJMAIN-AF" x="36" y="22"><path stroke-width="10" id="MJMAIN-AF" d="M69 544V590H430V544H69Z"></path></use></g><use transform="scale(1.73)" href="#MJMAIN-29" x="3005" y="0"><path stroke-width="10" id="MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></use><use transform="scale(1.223)" href="#MJMAIN-32" x="4807" y="688"><path stroke-width="10" id="MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></use></g></g></g></g></g></g></svg>)\n",
        "\n",
        "\n",
        "If the two variables are positively correlated, a large response from cell A will be matched with a large response in cell B. If they are weakly correlated, the response size of cell A will have no relationship with the response size of cell B. And if they are negatively correlated, cell B will have small responses when cell A has large responses.\n",
        "\n",
        "If two neurons are highly correlated, this could be due to a direct connection between the neurons or a shared input.\n",
        "\n",
        "\n",
        "\n",
        "![pearson-2-small.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAj0AAADSCAMAAACWwoFNAAAA4VBMVEX//////9v39/f//7bb///b/9vv7++2///m5ua2/9vb2//e3t7/25Db29vW1tbb25DMzMyQ2//FxcWQ29v/tmbbtra9vb3btma2tra1tbWtra22tmZmtv+lpaXbkDqZmZmQkNuQkLaUlJS2kDqQkJCMjIyEhIQ6kNu2ZmZ7e3s6kLZzc3OQZma2ZgBra2tmZpBmZmZaWlo/SMxRUVEAZraQOgBKSkoAZmZmOjo6OpBCQkJmOgA6OmY6OjozMzMAOpApKSkhISFmAAAZGRk6ADo6AAAQEBAAAGYICAgAADoAAAD1GQDMAAANY0lEQVR42u3dCXfiyBEAYBk7MokIK8+wzJhY8sYZxnGIJxyGTZwYW54Bj+v//6C8loQAHejqq0TVe/s8ayPo4+vqkrgMwzAeASwDd5hr1F0w10OsTe8DwAy5njuACerme1ib7gEA9FHjsVgXbMyZExy0yxYAPBOznhnrwiPa5o8AYI1yAmwAz1viTvwDfwEA1trB9ls/wtj05cg2FrY1XGqSOl/gpvS+tYbHyWQGa6R71zLAj7V4WGg07N/Lp5DR0DKGQ8N0UC5fYwIzZzaYrNcm6akbl063ymFDtKe8pmMaxsw2jMGA9CgKvHqCsh/xDJAe0kN6SA8GPSdzgOeznV90Vrekh/QUxXPl7vI5mQPpwaBHyLIvqacHz2dMUPQLF/DpSQzkEegRs+zL6Qke0oWHLWB8ehIDeQx6xCz7uJ4eu/T5EMnY/p8fp6/vF+w2b+fhRPxz/F90ehIDeQR6BC37mJ5e3Mt+dFZMT2e10eO+f0RX9yQGshl6lCz7ZO6JUnp+Izqr25M5/OPPf9JQT+ZoxgeyGXrULPu4ns7qUEHwx/11ex/MCmuYbnqyRzM+kI3JPQqWfTk9yZpB49yTMZrNzD3ZE+cCwJugZZ/cuQ6OKisa/POVzipIfKevguqeS++plp7M0Wxo3aNk2adUzXl8/EUd6mHLWswidgDE6GnoOZeSZa/t81yWM6ilJ3s0o4FsWtUsf9k39VnSQ6N5jNeaxQQ9x056SA/pIT2kh/Twj+l0OiU9pKcynmmmINJDegrpSRVEeo5Pj+30q+lJAJKhB0iPVnrGsDT48JGgBwC01NN37OPU89UbV9+9ppR7/FjC+Dj11Kt/qO4JErj3lfSQHr9vVPdIOvNqnJ4DVyRIj8jT9gbpmZIe8XZ00TOCBWc9yPzgeaZiM7ga6RnDEy89xhSjH3TPVCi53pMRZa545p9zIeSDQM/+qtRJD+czdnzpR3s98SHFqgfy9eBLP5rrSS5HpHqyn+vYu1qILP3orSdlMBude7D50VlP6kA2uO7Bt33pqydjETZfD6L0o62ezCFU8voeqXrw+NFUT5nha+Rz7Dj4aKmn3NJr5is0UKQfHfWUHLjyepyXhfZ6UKQf/fTk2oHaer7CGoEeBH5005OfdxLX3crr6V4PUOjRfvvSTE+R0SqZe9rtFsa6B0X60UpPtaWWo+c7DBDriY0JkB7OaTpHz1rz7/3M0tO2zMS4iHxnEG49lXN0jh6ra6LUM9u+22aHD+UezvVhQ9+Rs6NH2+pZhh4QaaexeqKdS2M/EvTkb9b1RkaKnlbblKwHw9mXBrmn7rKSoudO2He+F34vad44QTP1CLUjSc+Ix9sn6unJST8qzscU6+GxnUvR0+5a+Tcyq1yYLPM+9oPDhTL3LL0PSvFoVDW/wLVYPbpVz/X1QOVruZxGQh89HtyI1sOlev7gLXXRM3DaKu3opKfShcnSn8BSf+AGvEokZXUPvxR8fJ/fU3fs2o6DWg/P7TuuZzSyG65Hm4s/SvTwLf3ieqBK9YFMjybVswo9FTre9rx2UT2LRb/5evRIP/L1VFo1FoB1DHWPdWCVaOhHtp6KGbflOK1j0NM9sEo03L4k6xHR3Vp6zMtLnfQcWiUaph+pesSslVp6bABTIz3IqmeJekR1tJae7nqNWo9aP/L0COvk0X/LiTo+svQIXCH0HTnxwYVm6RGaXUlPbIDlvdJHhh7BOzPpiW9fTco9oss60qOsehaup1in7Mk30oOvehasp+iCcGps1Uel59tEpw9NEKuncHco9xQMOPy+asl+ROqJdUVULUe5R9n2JU5P4iKEqPNIqnuUpR9hepKdqIvHyng9JelR5keQHhEduMlIXqRH2fYlRI8Y/APPIz16pZ8FYvkS9Vh3X1HpkTQJC8S7rkQ9lwAtXHqkzEM5PY630M1OUk+/3+b+GPajsE94nkk761Wt5wZeMv8GhqKXmiTfkXNtIIqZjCtuBSB4jkI97HKOmpe5xfX8/OmQntLp56XKu+DK6TGt7E0BVL1EMq6n1TJIT2k/EvToVfDQGTvH7Wv/YxIl61H42mzSo2xu+OhR+r4Q0qNsfnjoUfyWxpieqbahTo+ok+GFjR1PTM90ioyPHD1iZqm2HoF2WpZFerROPzX1CM07TrEvYSM9yiZrofG7qCvpobpH4nzV0SO64Km0c9E5l8Ttq7oebT45mPQom7bKevT51Gl5eoQ8BzKT/eltHP1U1KPTR5ZL09Nar+0G6OG48hc2cjsS9ZgAHxqhh9sEVtGj2TdFydu5+n1TXz1QbQ5bcvVo9y11NfV0bUtp8znpKft2OS7TuLCR26mt5wm+NUFP+bfLcZjKknp0/HrDmnoWP++O6Yz98PYFtfRYVgtX4qmvp2W2jlVP7XeLx/Qc+ogGXb/Wma4W8vOTiSf9un9hPSXsWJNxi/Tg0FP07Cv9A5aK7lxlEk9f7idok57DO/N4YtWvngvp4bJpUe7RSY8J0K8/vYV2LlQFD+nhknuM6hcPC+jRHA/pEXH2xUmP7nZID28/Jjc9+tshPQrTz2E9COyQHoV+Fjp9/C/pQbZ9ZetBYof0KEw/mXqw2CE9Cv1k6JniwUN6hPlpV9KDyQ7pEZl+WuX1oLKToafdbZMeDn66JfVMkeFJ1zODCenhkn7aiT9k60FnJ0PPBMakR8D2tU9jX88hO4BKj9mW/0XZIF7PcOIo8NMtpOcgHgBMehRExREqpWcJM7XbV6aenE0LV+5RwqdhuSdt+9oHEulBWPDQGbtMP+GrTlP14MVDeqRuXyl6ENshPfL82K00PZjtkB6pZ1+tPSh7egzSQ3pyti8zQw/W4Sc9cv3E9RiI7ZAeFXziZ+ykR2BY19fo9ez7IT3y4ubAZegZohkgPSpi8PLSCD0G6aG6h0PZPCU9pKeKG9JDemriIT1AeuqlnmPWo8krltDp2fkT5Z4i0Xrx7MbrcSY3h/ik/YXqnkJ68j9BCb+eGSzLHkJ6iq1Lx2y8nszcQ3ronEtENFqP5QxID+mpqOem2FdTkh7SkxLX8EJ6DGMwGZIeqnsqxhg80kN6Kueer6SH9FDdQ3pID+khPaSH9AjV88H5QHpIT0U9j/p/Bhfp4R8Fk0aeHgSfwUV6+McEFlT3kJ6KMS625ZAe0kPnXHoEkJ5j08Pv1c2VXilNejDr4fnieMo9lHuo7iE9VDWTHtJDekgP6SE9pIf0kB7SQ3pID+khPZLizkGvxzRJj6KwYWQi12MtLcx6+ibincsDr49851quh4j1OPv4cekZAcBjH7WeYbwHqPSYsIf/ZTJCFBNgsRwg1mOxHkxsrHXPbA//wMEULPfAerJfOoyfZpjiu78CHrfZ/9JCFEO/8QMDY7DckyicTUyjb3X9BXC37cTT0yOiWPr2AeVFkjU8WsivTjn7dtBdXPPto5yEwdoxsMcMZpgXwBJggrT9d/gvjJu4F4AFy75BoeyCJ+4FMJyYNIcUVfHTEFBQUFBQUFBQUFBQUFBQYIvOKngSDK4Sf3Lh7Tz+r5S4D46/zX+k57OsB+AZJ3MAeAh/xh+y8KjIaSvn7shv5Mkc3i9OX9P4FIkesBZ3Vrl6epWnsnS4IWY3n7TytsrojtjGvV+w6X/IWIUHVZ2+Btw7q9v8KdmZkZy75ZBPrwyj8+PCqMpHVlt5dUdVIw/rcQ/nJBcKL4i93cAF0XpYpyrrkddWXt1R1Uimh22qtyxh+xh6QWvZAnT9X/Xg+Q9z9jsfC/vdZn+9ZzfcSfjR8fCw+bG5vT8jblBiRXd7tj3K/12G4ZLD/ePjnD1kMNy9varMDfqmTVtLdydsYS+oNp//FmtkxjwJ3VYheLS389NXeDj993/OXLhy/c3/Pmja89npK9waJ1/+atzDQ7Q2T+Y77dscH3Rs8yO6PfvvZA63ndXb+fZuo6NYMx5OX3ksoc4Pv5B7/oUN9+b+t21kDdKmrWW7E7bwE9O0ejtPNjJ1ngTvXEGCvGKr6/3jPBjr3kZP8C+XtebHRXiSFqDxS+5tgg2OvwirhuBHdPtNT6LO+jfYHuVGD8dhuFlBBuGWHN5/WKbd6tXW8t3xW/gXeDBO5puJ221k6jzJ0MN+shE6mW/Tt98q/1+nr+8Xv34+C262k7iuIj2b48OxD35Etw9/6/r3Hd3t9ij/lIKbHn+c/eHe3P+2jTq1tVJ3DMP4+9jPPclGps+TvNwT7K5B+t5plXEPv3/5LZqIKOEEq/Tz5+3xsRkJbx/uBhCfke165qqHVQYFco/qtlbqTpgl386NZCPT50nk1ajbiFFQCzz4ObAXtOr218+f/ATYWb3/6zwslKP6P7je45f8m+ONXpAvwx+b2/f8HYGt2727jY5y/WTMo8vhhZFgWUT3H1X57OqCNm0t252whf8bn0flgltknkReaw7yR1C4B+U8qwgYDPa7p3D/vA+6cQ+7Vz39HXlzOSs6PjwrCKeE3f6T/7+bC9M7dxsexf7y+ytA7SnZXpS9f7/Ytmrnyjj7ox5trdCdoIW/rMInCFIamT5PFBRbUs9nUdlMQVEmTr/8tnMOQEFR4SId4aGgoGh+/B+J99cBQ/he/gAAAABJRU5ErkJggg==)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hPZLPF4Cpga3"
      },
      "id": "hPZLPF4Cpga3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation**\n",
        "\n",
        "To assess how learning changes neural activity before and after learning, we'll take the good ROIs in the dataset and compare its activity to every other good ROI in the dataset. In other words, we'll compute pairwise correlation coefficients. We'll use the `corrcoef` function from numpy to help us out.\n",
        "\n",
        "First, let's shape the data we need to run the function. Let's focus on the spontaneous activity epoch that occurred before and after learning as this gives us a neutral read out of neural activity.\n",
        "\n",
        "\n",
        "# **Discuss**\n",
        "What does spontaneous activity mean? Why is it useful?"
      ],
      "metadata": {
        "id": "YVP35MfksXUc"
      },
      "id": "YVP35MfksXUc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Get dff for the spontaneous epochs**  \n",
        "Let's shape the dff array to get the frame periods during the spontaneous epochs before and after learning (spont and spont_post, respectively).\n",
        "\n",
        "Note that the epoch order and stimulus naming scheme can vary across sessions. Be sure to check the epoch table before doing any epoch-specific analyses."
      ],
      "metadata": {
        "id": "R0s-Hy88nhF6"
      },
      "id": "R0s-Hy88nhF6"
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_table"
      ],
      "metadata": {
        "id": "FBMfs_-KOoC1"
      },
      "id": "FBMfs_-KOoC1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to index into the dff array in order to just choose the section that is during the spontaneous epochs. To index into an array, we need the index of the array that corresponds to the start_time and stop_time. We've already calculated this for you, and it's in the epoch (and trial) tables as the **start_frame** and **stop_frame** respectively."
      ],
      "metadata": {
        "id": "t55gYgEszMZB"
      },
      "id": "t55gYgEszMZB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the start and stop frames for the spontaneous periods before (spont) and after (spont_post) learning.\n",
        "spontaneous_pre_start = epoch_table[epoch_table.stimulus_name == 'spont'].start_frame.values[0]\n",
        "spontaneous_pre_stop = epoch_table[epoch_table.stimulus_name == 'spont'].stop_frame.values[0]\n",
        "\n",
        "# The last spontaneous period is the last spontaneous epoch\n",
        "spontaneous_post_start = epoch_table[epoch_table.stimulus_name == 'spont_post'].start_frame.values[0]\n",
        "spontaneous_post_stop = epoch_table[epoch_table.stimulus_name == 'spont_post'].stop_frame.values[0]\n"
      ],
      "metadata": {
        "id": "iG7b25hWtdrL"
      },
      "id": "iG7b25hWtdrL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index into the dff traces array to limit to the relevant time points\n",
        "dff_pre = dff_traces[spontaneous_pre_start:spontaneous_pre_stop, :]\n",
        "# Transpose so shape is n_neurons x n_frames\n",
        "dff_pre = dff_pre.T\n",
        "\n",
        "print(dff_pre.shape)\n",
        "\n",
        "dff_post = dff_traces[spontaneous_post_start:spontaneous_post_stop, :]\n",
        "dff_post = dff_post.T\n",
        "print(dff_post.shape)"
      ],
      "metadata": {
        "id": "Xay4BZk7t0hV"
      },
      "id": "Xay4BZk7t0hV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "49e68108",
      "metadata": {
        "id": "49e68108"
      },
      "source": [
        "Visualize the dFF traces for each spontaneous period as a heatmap."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot as heatmap\n",
        "plt.imshow(\n",
        "    dff_pre,\n",
        "    vmin=0,\n",
        "    vmax=5,\n",
        "    cmap='magma',\n",
        "    origin='lower',\n",
        "    aspect='auto',\n",
        "    interpolation='none'\n",
        ")\n",
        "\n",
        "plt.colorbar(label='dFF')\n",
        "plt.xlabel('2P frames')\n",
        "plt.ylabel('ROI ID')\n",
        "plt.title('Spontaneous pre')\n"
      ],
      "metadata": {
        "id": "ewhtqq8U0OMv"
      },
      "id": "ewhtqq8U0OMv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise:** Repeat the same for spontaneous post epoch.\n"
      ],
      "metadata": {
        "id": "_YVnrwVDDIh0"
      },
      "id": "_YVnrwVDDIh0"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xo6sCWOnXAjj"
      },
      "id": "xo6sCWOnXAjj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ffa7047",
      "metadata": {
        "id": "2ffa7047",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Click to show answer\n",
        "\n",
        "# Set up figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot as heatmap\n",
        "plt.imshow(\n",
        "    dff_post,\n",
        "    vmin=0,\n",
        "    vmax=5,\n",
        "    cmap='magma',\n",
        "    origin='lower',\n",
        "    aspect='auto',\n",
        "    interpolation='none'\n",
        ")\n",
        "\n",
        "plt.colorbar(label='dFF')\n",
        "plt.xlabel('2P frames')\n",
        "plt.ylabel('ROI ID')\n",
        "plt.title('Spontaneous post')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filter dff for valid somas**\n",
        "\n",
        "Remember that not all of these dff traces are from valid somas, so we should filter the data we include in our correlations analysis. It also looks like there are some nans in the array that should be filtered out.\n"
      ],
      "metadata": {
        "id": "XmOyz-X74ld6"
      },
      "id": "XmOyz-X74ld6"
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dff_pre = dff_pre[filtered_roi_table.index.values, :] # Filter for rows in filtered_roi_table\n",
        "mask = np.isnan(filtered_dff_pre).any(axis=1) # Filter out nans\n",
        "filtered_dff_pre = filtered_dff_pre[~mask]\n",
        "print('filtered dff pre shape (nframes, nrois):',np.shape(filtered_dff_pre))\n",
        "\n",
        "filtered_dff_post = dff_post[filtered_roi_table.index.values, :] # Filter for rows in filtered_roi_table\n",
        "mask = np.isnan(filtered_dff_post).any(axis=1) # Filter out nans\n",
        "filtered_dff_post = filtered_dff_post[~mask]\n",
        "print('filtered dff post shape (nframes, nrois):',np.shape(filtered_dff_post))"
      ],
      "metadata": {
        "id": "BaeKEJlfGdNX"
      },
      "id": "BaeKEJlfGdNX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot filtered_dff_pre as a heatmap\n",
        "\n",
        "# Set up figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Use imshow to plot heatmap\n",
        "plt.imshow(\n",
        "    filtered_dff_pre,\n",
        "    vmin=0,\n",
        "    vmax=5,\n",
        "    cmap='magma',\n",
        "    origin='lower',\n",
        "    aspect='auto',\n",
        "    interpolation='none'\n",
        ")\n",
        "plt.colorbar(label='dFF')\n",
        "plt.xlabel('2P frames')\n",
        "plt.ylabel('ROI ID')\n",
        "plt.title('Spontaneous pre')\n"
      ],
      "metadata": {
        "id": "mOp62Cu56Jcv"
      },
      "id": "mOp62Cu56Jcv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot filtered_dff_post as a heatmap\n",
        "\n",
        "# Set up figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Use imshow to plot a heatmap\n",
        "plt.imshow(\n",
        "    filtered_dff_post,\n",
        "    vmin=0,\n",
        "    vmax=5,\n",
        "    cmap='magma',\n",
        "    origin='lower',\n",
        "    aspect='auto',\n",
        "    interpolation='none'\n",
        ")\n",
        "plt.colorbar(label='dFF')\n",
        "plt.xlabel('2P frames')\n",
        "plt.ylabel('ROI ID')\n",
        "plt.title('Spontaneous post')\n"
      ],
      "metadata": {
        "id": "F_33b_Wv7KNm"
      },
      "id": "F_33b_Wv7KNm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Discuss:** What do you notice about the spontaneous activity?"
      ],
      "metadata": {
        "id": "asSOSHOKBpxu"
      },
      "id": "asSOSHOKBpxu"
    },
    {
      "cell_type": "markdown",
      "id": "7a34b5f4-ad0c-43fc-b0bd-774c41b2987a",
      "metadata": {
        "id": "7a34b5f4-ad0c-43fc-b0bd-774c41b2987a"
      },
      "source": [
        "# **Quantifying correlations**\n",
        "\n",
        "Now that we've gotten dff arrays for the spontaneous epochs that happened before and after the BCI task, let's compute pairwise correlations between all neurons in each epoch.\n",
        "\n",
        "First, quantify the correlation between every cell pair's dff traces for the pre and post spontaneous periods using [np.corrcoef](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html).\n",
        "    \n",
        "We will save the output to two variables called `correlations_pre` and `correlations_post` so we can use them later in our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c3ecddc",
      "metadata": {
        "id": "0c3ecddc"
      },
      "outputs": [],
      "source": [
        "correlations_pre = np.corrcoef(filtered_dff_pre)\n",
        "correlations_post = np.corrcoef(filtered_dff_post)\n",
        "\n",
        "correlations_pre.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16def8e6-4976-4e0c-b83f-2addb84e1cf6",
      "metadata": {
        "id": "16def8e6-4976-4e0c-b83f-2addb84e1cf6"
      },
      "source": [
        "Let's plot the matrix of correlations before learning as a heatmap.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot correlations pre as a heatmap\n",
        "plt.imshow(\n",
        "    correlations_pre,\n",
        "    vmin=-0.1,\n",
        "    vmax=0.1,\n",
        "    cmap='RdBu',\n",
        "    origin='lower',\n",
        "    aspect='auto',\n",
        "    interpolation='none'  # imshow uses a default smoothing, turn this off\n",
        ")\n",
        "\n",
        "plt.colorbar(label='Correlation')\n",
        "plt.xlabel('ROI #')\n",
        "plt.ylabel('ROI #')\n",
        "plt.title('Correlations pre')\n"
      ],
      "metadata": {
        "id": "hO5FA11Ppgjk"
      },
      "id": "hO5FA11Ppgjk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise:** Repeat the same for the correlations after learning.\n",
        "\n",
        "Did the correlations change?"
      ],
      "metadata": {
        "id": "HjhE4QBPCEZ-"
      },
      "id": "HjhE4QBPCEZ-"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZ1aAKEqXCa0"
      },
      "id": "bZ1aAKEqXCa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78df01c",
      "metadata": {
        "id": "c78df01c",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title  Click to show answer\n",
        "# Plot correlations pre as a heatmap\n",
        "plt.imshow(\n",
        "    correlations_post,\n",
        "    vmin=-0.1,\n",
        "    vmax=0.1,\n",
        "    cmap='RdBu',\n",
        "    origin='lower',\n",
        "    aspect='auto',\n",
        "    interpolation='none'  # imshow uses a default smoothing, turn this off\n",
        ")\n",
        "\n",
        "plt.colorbar(label='Correlation')\n",
        "plt.xlabel('ROI #')\n",
        "plt.ylabel('ROI #')\n",
        "plt.title('Correlations post')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aa453e4-acd5-45f3-b556-8c682ac9179a",
      "metadata": {
        "id": "3aa453e4-acd5-45f3-b556-8c682ac9179a"
      },
      "source": [
        "# **Remove duplicate pairs**\n",
        "\n",
        "To quantify differences in the distribution of pairwise correlation values, we only want to count each pair once and we dont want to include each cell's correlation to itself (which is always 1, along the diagonal).\n",
        "\n",
        "We can use [`np.triu_indices`](https://numpy.org/devdocs/reference/generated/numpy.triu_indices.html), which will return the indices for the upper triangle above the kth diagonal. Then, we'll use these indices to filter our correlations_pre and post arrays."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triu_indices = np.triu_indices(correlations_pre.shape[0], k = 1)\n",
        "triu_indices # returns a tuple of 2 ndarrays of shape nframes"
      ],
      "metadata": {
        "id": "VgyWdKUELaJo"
      },
      "id": "VgyWdKUELaJo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, filter correlations_pre and correlations_post for indices we just grabbed\n",
        "\n",
        "pre_vals = correlations_pre[triu_indices[0], triu_indices[1]]\n",
        "post_vals = correlations_post[triu_indices[0], triu_indices[1]]\n",
        "\n",
        "# This flattens the array\n",
        "print(correlations_pre.shape)\n",
        "print(pre_vals.shape)"
      ],
      "metadata": {
        "id": "m3IcuXnkNjOc"
      },
      "id": "m3IcuXnkNjOc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c2cc5fc6-d99b-4d83-a312-e307da06ee80",
      "metadata": {
        "id": "c2cc5fc6-d99b-4d83-a312-e307da06ee80"
      },
      "source": [
        "# **Plot the distribution of correlation values for spontaneous pre and spontaneous post.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define bin edges\n",
        "bins = np.linspace(-0.1, 0.1, 100)\n",
        "\n",
        "# Plot histograms\n",
        "plt.hist(pre_vals, bins=bins, color='green', label='pre', histtype='step')\n",
        "plt.hist(post_vals, bins=bins, color='purple', label='post', histtype='step')\n",
        "\n",
        "plt.title('Correlations before and after BCI learning')\n",
        "plt.xlabel('r value')\n",
        "plt.ylabel('# cell pairs')\n",
        "plt.xlim(-0.1, 0.1)\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "9x82yq4PqXV9"
      },
      "id": "9x82yq4PqXV9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6a3ac49c-3747-4bf1-a898-4e43a7a7861d",
      "metadata": {
        "id": "6a3ac49c-3747-4bf1-a898-4e43a7a7861d"
      },
      "source": [
        "# **Evaluate the pairwise correlations: run a t-test**\n",
        "\n",
        "Did the correlations in neural activity change after the BCI task?\n",
        "\n",
        "We can check for statistical differences in the distribution of pairwise correlations. We'll first flatten the matrix of correlations into a 1D array, then apply a t-test using [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\n",
        "\n",
        "Are the distributions statistically different?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean of the pre and post distributions\n",
        "\n",
        "print('mean pre:', pre_vals.mean())\n",
        "print('mean post:', post_vals.mean())"
      ],
      "metadata": {
        "id": "pa7PEBYPQd5P"
      },
      "id": "pa7PEBYPQd5P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21fba801-cdf2-42c6-ae66-d2499c696ca5",
      "metadata": {
        "id": "21fba801-cdf2-42c6-ae66-d2499c696ca5"
      },
      "outputs": [],
      "source": [
        "# Run the stats!\n",
        "t, p_val = stats.ttest_ind(pre_vals, post_vals)\n",
        "print(p_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what does this mean? if <0.05 then, yes"
      ],
      "metadata": {
        "id": "UFCDjknwqkYB"
      },
      "id": "UFCDjknwqkYB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise**\n",
        "\n",
        "From the correlations arrays, get the correlations between the conditioned neuron and all other good ROIs. Plot the distribution of correlations before and after learning. Did the correlations change?\n",
        "\n",
        "**Hint** From the original correlations_pre and correlations_post, subselect the data of interest. Since we're looking at the correlations of one neuron, we don't need to use np.triu to remove duplicates, but instead we do need to handle the self-correlations."
      ],
      "metadata": {
        "id": "-1ktngd_QTDO"
      },
      "id": "-1ktngd_QTDO"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LxB8Ndinyf0A"
      },
      "id": "LxB8Ndinyf0A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the means and stats here"
      ],
      "metadata": {
        "id": "zGE1cJh2yg0X"
      },
      "id": "zGE1cJh2yg0X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to show answer\n",
        "\n",
        "# Reshape data to get only dff for conditioned neuron index\n",
        "\n",
        "# Get conditioned neuron index\n",
        "cn_index = trials.closest_roi[0]\n",
        "\n",
        "cn_correlations_pre = correlations_pre[cn_index,:]\n",
        "cn_correlations_post = correlations_post[cn_index,:]\n",
        "\n",
        "# Remove the self-correlation at index of the neuron we sub-selected\n",
        "mask = np.arange(len(cn_correlations_pre)) != cn_index\n",
        "cn_correlations_pre = cn_correlations_pre[mask]\n",
        "cn_correlations_post = cn_correlations_post[mask]\n",
        "\n",
        "# Define shared bin edges\n",
        "bins = np.linspace(-0.1, 0.1, 100)\n",
        "\n",
        "# Plot histograms\n",
        "plt.hist(cn_correlations_pre, bins=bins, color='green', label='pre', histtype='step')\n",
        "plt.hist(cn_correlations_post, bins=bins, color='purple', label='post', histtype='step')\n",
        "\n",
        "plt.title('Correlations with Conditioned Neuron Before and After BCI Learning')\n",
        "plt.xlabel('r value')\n",
        "plt.ylabel('# cell pairs')\n",
        "plt.xlim(-0.1, 0.2)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "z-NWYhRSWi6Y",
        "cellView": "form"
      },
      "id": "z-NWYhRSWi6Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to show answer\n",
        "# Calculate the mean of the pre and post distributions\n",
        "\n",
        "print('mean pre:', cn_correlations_pre.mean())\n",
        "print('mean post:', cn_correlations_post.mean())\n",
        "\n",
        "# Run the stats!\n",
        "t, p_val = stats.ttest_ind(cn_correlations_pre, cn_correlations_post)\n",
        "print('p_val:', p_val)"
      ],
      "metadata": {
        "id": "DHw5cr7mVBwE",
        "cellView": "form"
      },
      "id": "DHw5cr7mVBwE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Sdv7FnbjW493"
      },
      "id": "Sdv7FnbjW493"
    },
    {
      "cell_type": "markdown",
      "id": "a834d618-7135-47de-80cb-73cf03010a7f",
      "metadata": {
        "id": "a834d618-7135-47de-80cb-73cf03010a7f"
      },
      "source": [
        "# **Questions and analyses to explore further:**\n",
        "\n",
        "* How do the pairwise correlations during the spontaneous period change from session-to-session?\n",
        "\n",
        "* Which neuron pairs have the largest changes in correlations after BCI learning? Do they increase or decrease? Are they also correlated to the conditioned neuron? What does their activity look like during the BCI task? Get the conditioned neuron ID from the BCI trials table and compare it's activity to other cells in the population.\n",
        "   \n",
        "* Do correlated neurons tend to have stronger connections? Use the photostimulation periods to measure connection strength across neurons based on their response latency and relate to spontaneous activity correlations.\n",
        "    \n",
        "* How does the activity of the conditioned neuron change throughout the BCI task? Quantify it's mean activity across trials in the behavior block. How does the activity relate to the animal's behavior?\n",
        "        \n",
        "* Do non-conditioned neurons change their activity during the BCI task? Were these cells more highly connected to the conditioned neuron prior to BCI learning?\n",
        "    \n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}